name: Deploy AI Document Parser

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      aws_region:
        description: 'AWS Region to deploy to'
        required: false
        default: 'us-east-1'
      environment:
        description: 'Environment to deploy to'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}
    outputs:
      deployment_status: ${{ job.status }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set AWS Region
        id: set-region
        run: echo "AWS_REGION=${{ github.event.inputs.aws_region || secrets.AWS_REGION || 'us-east-1' }}" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        
      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      # Clear Terraform state to avoid conflicts
      - name: Clear Terraform state for conflict-prone resources
        working-directory: ./terraform
        run: |
          terraform state rm aws_api_gateway_resource.api_resource || true
          terraform state rm aws_api_gateway_resource.process_document || true
          terraform state rm aws_api_gateway_resource.task || true
          terraform state rm aws_api_gateway_resource.task_id || true
          terraform state rm aws_lambda_function.ai_doc_parser || true
          terraform state rm aws_api_gateway_rest_api.api || true
        continue-on-error: true

      # Basic resource imports
      - name: Import basic resources
        working-directory: ./terraform
        run: |
          # Import ECR repository if it exists
          if aws ecr describe-repositories --repository-names ai-doc-parser-ecr 2>/dev/null; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_ecr_repository.ai_doc_parser ai-doc-parser-ecr || true
          fi
          
          # Import IAM role if it exists
          if aws iam get-role --role-name ai-doc-parser-lambda-role 2>/dev/null; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_iam_role.lambda_role ai-doc-parser-lambda-role || true
          fi
          
          # Import S3 bucket if it exists
          if aws s3api head-bucket --bucket ai-doc-parser-s3 2>/dev/null; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_s3_bucket.ai_doc_parser ai-doc-parser-s3 || true
          fi
          
          # Import API Gateway if it exists
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text || echo "")
          if [ ! -z "$API_ID" ]; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_api_gateway_rest_api.api $API_ID || true
              
            # Import API Gateway resources if they exist
            ROOT_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/'].id" --output text)
            
            # Import /api resource
            API_RESOURCE_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api'].id" --output text)
            if [ ! -z "$API_RESOURCE_ID" ]; then
              terraform import \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                aws_api_gateway_resource.api_resource $API_ID/$API_RESOURCE_ID || true
            fi
            
            # Import /api/process-document resource
            PROCESS_DOC_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api/process-document'].id" --output text)
            if [ ! -z "$PROCESS_DOC_ID" ]; then
              terraform import \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                aws_api_gateway_resource.process_document $API_ID/$PROCESS_DOC_ID || true
            fi
            
            # Import /api/task resource
            TASK_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api/task'].id" --output text)
            if [ ! -z "$TASK_ID" ]; then
              terraform import \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                aws_api_gateway_resource.task $API_ID/$TASK_ID || true
            fi
            
            # Import /api/task/{task_id} resource
            TASK_ID_PATH=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api/task/{task_id}'].id" --output text)
            if [ ! -z "$TASK_ID_PATH" ]; then
              terraform import \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                aws_api_gateway_resource.task_id $API_ID/$TASK_ID_PATH || true
            fi
          fi
        continue-on-error: true

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Create ECR Repository and IAM Roles
        id: create_ecr_iam
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_ecr_repository.ai_doc_parser \
            -target=aws_iam_role.lambda_role \
            -target=aws_iam_role_policy.lambda_s3_policy \
            -target=aws_iam_role_policy_attachment.lambda_logs
        continue-on-error: true

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v2
        
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build and Push Docker Image for Lambda
        id: build_push
        run: |
          # Get ECR repository URI
          ECR_REPO=$(aws ecr describe-repositories --repository-names ai-doc-parser-ecr --query 'repositories[0].repositoryUri' --output text)
          
          # Login to ECR
          aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_REPO
          
          # Verify Dockerfile is using AWS Lambda base image
          if ! grep -q "FROM public.ecr.aws/lambda/python:" Dockerfile; then
            echo "ERROR: Dockerfile must use the AWS Lambda base image (public.ecr.aws/lambda/python)"
            cat Dockerfile
            exit 1
          fi
          
          # Build image specifically for Lambda (no buildx)
          echo "Building image for Lambda..."
          docker build -t $ECR_REPO:latest .
          
          # Push the image
          echo "Pushing image to ECR..."
          docker push $ECR_REPO:latest
          
          echo "The image has been built and pushed to $ECR_REPO:latest"

      - name: Deploy S3 Bucket
        id: deploy_s3
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_s3_bucket.ai_doc_parser \
            -target=aws_s3_bucket_ownership_controls.ai_doc_parser
        continue-on-error: true

      - name: Create or Update Lambda Function
        id: deploy_lambda
        run: |
          # Get ECR repository URI
          ECR_REPO=$(aws ecr describe-repositories --repository-names ai-doc-parser-ecr --query 'repositories[0].repositoryUri' --output text)
          
          # Check if Lambda exists
          if aws lambda get-function --function-name ai-doc-parser-lambda > /dev/null 2>&1; then
            echo "Updating Lambda function..."
            aws lambda update-function-code \
              --function-name ai-doc-parser-lambda \
              --image-uri $ECR_REPO:latest
          else
            echo "Creating Lambda function..."
            # Create Lambda with more parameters
            aws lambda create-function \
              --function-name ai-doc-parser-lambda \
              --role arn:aws:iam::$(aws sts get-caller-identity --query 'Account' --output text):role/ai-doc-parser-lambda-role \
              --package-type Image \
              --code ImageUri=$ECR_REPO:latest \
              --timeout 90 \
              --memory-size 4096 \
              --architectures x86_64 \
              --ephemeral-storage Size=5120 \
              --environment "Variables={API_KEY=${{ secrets.API_KEY }},DB_HOST=${{ secrets.DB_HOST }},DB_NAME=${{ secrets.DB_NAME }},DB_PASSWORD=${{ secrets.DB_PASSWORD }},DB_PORT=${{ secrets.DB_PORT }},DB_USER=${{ secrets.DB_USER }},OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }},S3_BUCKET_NAME=ai-doc-parser-s3}"
          fi
          
          # Wait for Lambda to be ready
          echo "Waiting for Lambda to be ready..."
          aws lambda wait function-active-v2 --function-name ai-doc-parser-lambda
          
          echo "Lambda function deployed successfully"

      - name: Deploy API Gateway
        id: deploy_api
        working-directory: ./terraform
        run: |
          # Update Terraform configuration to use the lambda without creating it
          cat > lambda_override.tf << 'EOT'
          # This file overrides the creation of the Lambda function
          # since we created it using the AWS CLI
          resource "aws_lambda_function" "ai_doc_parser" {
            function_name = "ai-doc-parser-lambda"
            image_uri     = "${aws_ecr_repository.ai_doc_parser.repository_url}:latest"
            role          = aws_iam_role.lambda_role.arn
            package_type  = "Image"
            memory_size   = 4096
            timeout       = 90
            ephemeral_storage {
              size = 5120
            }

            environment {
              variables = {
                API_KEY         = var.api_key
                DB_HOST         = var.db_host
                DB_NAME         = var.db_name
                DB_PASSWORD     = var.db_password
                DB_PORT         = var.db_port
                DB_USER         = var.db_user
                OPENAI_API_KEY  = var.openai_api_key
                S3_BUCKET_NAME  = aws_s3_bucket.ai_doc_parser.bucket
              }
            }
            
            # Prevent terraform from trying to create the Lambda
            # (Lambda was created by aws cli)
            lifecycle {
              ignore_changes = all
            }
          }
          EOT
          
          # Import Lambda into state
          LAMBDA_ARN=$(aws lambda get-function --function-name ai-doc-parser-lambda --query 'Configuration.FunctionArn' --output text)
          if [ ! -z "$LAMBDA_ARN" ]; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_lambda_function.ai_doc_parser $LAMBDA_ARN || true
          fi
          
          # Check if API Gateway exists and create/update appropriately
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text || echo "")
          
          if [ ! -z "$API_ID" ]; then
            # Get existing resources
            RESOURCES=$(aws apigateway get-resources --rest-api-id $API_ID)
            
            # Check if necessary paths exist
            API_RESOURCE_ID=$(echo "$RESOURCES" | grep -o '"path": "/api"' | wc -l || echo "0")
            PROCESS_DOC_RESOURCE=$(echo "$RESOURCES" | grep -o '"path": "/api/process-document"' | wc -l || echo "0")
            TASK_RESOURCE=$(echo "$RESOURCES" | grep -o '"path": "/api/task"' | wc -l || echo "0")
            TASK_ID_RESOURCE=$(echo "$RESOURCES" | grep -o '"path": "/api/task/{task_id}"' | wc -l || echo "0")
            
            # Only apply what's needed
            if [ "$API_RESOURCE_ID" -gt 0 ] && [ "$PROCESS_DOC_RESOURCE" -gt 0 ] && [ "$TASK_RESOURCE" -gt 0 ] && [ "$TASK_ID_RESOURCE" -gt 0 ]; then
              echo "All API resources already exist, applying only integrations and methods"
              
              # Add binary media types if not already present
              BINARY_TYPES=$(aws apigateway get-rest-api --rest-api-id $API_ID --query 'binaryMediaTypes' --output text)
              if ! echo "$BINARY_TYPES" | grep -q "multipart/form-data"; then
                aws apigateway update-rest-api \
                  --rest-api-id $API_ID \
                  --patch-operations '[{"op":"add","path":"/binaryMediaTypes/multipart~1form-data","value":""}]'
              fi
              if ! echo "$BINARY_TYPES" | grep -q "*/*"; then
                aws apigateway update-rest-api \
                  --rest-api-id $API_ID \
                  --patch-operations '[{"op":"add","path":"/binaryMediaTypes/*~1*","value":""}]'
              fi
              
              # Apply only the methods and integrations
              terraform apply -auto-approve \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                -target=aws_api_gateway_method.process_document_post \
                -target=aws_api_gateway_method.task_id_get \
                -target=aws_api_gateway_integration.process_document_integration \
                -target=aws_api_gateway_integration.task_id_integration \
                -target=aws_lambda_permission.api_gateway
            else
              # Create any missing resources
              TARGETS=""
              if [ "$API_RESOURCE_ID" -eq 0 ]; then
                TARGETS="$TARGETS -target=aws_api_gateway_resource.api_resource"
              fi
              if [ "$PROCESS_DOC_RESOURCE" -eq 0 ]; then
                TARGETS="$TARGETS -target=aws_api_gateway_resource.process_document"
              fi
              if [ "$TASK_RESOURCE" -eq 0 ]; then
                TARGETS="$TARGETS -target=aws_api_gateway_resource.task"
              fi
              if [ "$TASK_ID_RESOURCE" -eq 0 ]; then
                TARGETS="$TARGETS -target=aws_api_gateway_resource.task_id"
              fi
              
              # Apply the API Gateway
              terraform apply -auto-approve \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                $TARGETS \
                -target=aws_api_gateway_method.process_document_post \
                -target=aws_api_gateway_method.task_id_get \
                -target=aws_api_gateway_integration.process_document_integration \
                -target=aws_api_gateway_integration.task_id_integration \
                -target=aws_lambda_permission.api_gateway
              
              # Add binary media types
              aws apigateway update-rest-api \
                --rest-api-id $API_ID \
                --patch-operations '[{"op":"add","path":"/binaryMediaTypes/multipart~1form-data","value":""},{"op":"add","path":"/binaryMediaTypes/*~1*","value":""}]'
            fi
          else
            # Create the API Gateway from scratch
            terraform apply -auto-approve \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              -target=aws_api_gateway_rest_api.api \
              -target=aws_api_gateway_resource.api_resource \
              -target=aws_api_gateway_resource.process_document \
              -target=aws_api_gateway_resource.task \
              -target=aws_api_gateway_resource.task_id \
              -target=aws_api_gateway_method.process_document_post \
              -target=aws_api_gateway_method.task_id_get \
              -target=aws_api_gateway_integration.process_document_integration \
              -target=aws_api_gateway_integration.task_id_integration \
              -target=aws_lambda_permission.api_gateway
              
            # Get the API ID
            API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text)
            
            # Add binary media types
            if [ ! -z "$API_ID" ]; then
              aws apigateway update-rest-api \
                --rest-api-id $API_ID \
                --patch-operations '[{"op":"add","path":"/binaryMediaTypes/multipart~1form-data","value":""},{"op":"add","path":"/binaryMediaTypes/*~1*","value":""}]'
            fi
          fi
        continue-on-error: true

      - name: Deploy API Gateway Stage
        id: deploy_stage
        working-directory: ./terraform
        run: |
          # Create or update the deployment
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_api_gateway_deployment.prod
            
          # Get API URL directly from AWS CLI since Terraform may have warnings
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text)
          if [ ! -z "$API_ID" ]; then
            API_URL="https://$API_ID.execute-api.${{ env.AWS_REGION }}.amazonaws.com/prod"
            echo "API Gateway URL: $API_URL"
            # Create a file to store the URL for future reference
            echo $API_URL > api_url.txt
          else
            echo "API Gateway not found"
            exit 1
          fi