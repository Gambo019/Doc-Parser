name: Deploy AI Document Parser

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      aws_region:
        description: 'AWS Region to deploy to'
        required: false
        default: 'us-east-1'
      environment:
        description: 'Environment to deploy to'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}
    outputs:
      deployment_status: ${{ job.status }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set AWS Region
        id: set-region
        run: echo "AWS_REGION=${{ github.event.inputs.aws_region || secrets.AWS_REGION || 'us-east-1' }}" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        
      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Check if resources already exist
        id: check_resources
        run: |
          # Check if IAM role exists
          if aws iam get-role --role-name ai-doc-parser-lambda-role 2>/dev/null; then
            echo "IAM_ROLE_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "IAM_ROLE_EXISTS=false" >> $GITHUB_OUTPUT
          fi
          
          # Check if ECR repo exists
          if aws ecr describe-repositories --repository-names ai-doc-parser-ecr 2>/dev/null; then
            echo "ECR_REPO_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "ECR_REPO_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Import existing IAM role into Terraform state
        if: steps.check_resources.outputs.IAM_ROLE_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_iam_role.lambda_role ai-doc-parser-lambda-role
        continue-on-error: true

      - name: Import existing ECR repository into Terraform state
        if: steps.check_resources.outputs.ECR_REPO_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_ecr_repository.ai_doc_parser ai-doc-parser-ecr
        continue-on-error: true

      - name: Check if S3 bucket exists
        id: check_s3
        run: |
          if aws s3api head-bucket --bucket ai-doc-parser-s3 2>/dev/null; then
            echo "S3_BUCKET_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "S3_BUCKET_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Check if Lambda function exists
        id: check_lambda
        run: |
          if aws lambda get-function --function-name ai-doc-parser-lambda 2>/dev/null; then
            echo "LAMBDA_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "LAMBDA_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Check if API Gateway exists
        id: check_api
        run: |
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text)
          if [ ! -z "$API_ID" ]; then
            echo "API_EXISTS=true" >> $GITHUB_OUTPUT
            echo "API_ID=$API_ID" >> $GITHUB_OUTPUT
          else
            echo "API_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Import S3 bucket
        if: steps.check_s3.outputs.S3_BUCKET_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_s3_bucket.ai_doc_parser ai-doc-parser-s3
        continue-on-error: true

      - name: Import Lambda function
        if: steps.check_lambda.outputs.LAMBDA_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_lambda_function.ai_doc_parser ai-doc-parser-lambda
        continue-on-error: true

      - name: Import API Gateway
        if: steps.check_api.outputs.API_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_api_gateway_rest_api.api ${{ steps.check_api.outputs.API_ID }}
        continue-on-error: true

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Terraform Plan
        working-directory: ./terraform
        run: |
          terraform plan \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}"

      - name: Create ECR Repository and IAM Roles
        id: create_ecr_iam
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_ecr_repository.ai_doc_parser \
            -target=aws_iam_role.lambda_role \
            -target=aws_iam_role_policy.lambda_s3_policy \
            -target=aws_iam_role_policy_attachment.lambda_logs
        continue-on-error: true
        
      - name: Check ECR IAM creation status
        if: steps.create_ecr_iam.outcome != 'success'
        run: |
          echo "ECR and IAM creation failed. This might be because they already exist."
          echo "Continuing with deployment..."

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build and push Docker image
        id: build_push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          platforms: linux/amd64
          tags: ${{ steps.login-ecr.outputs.registry }}/ai-doc-parser-ecr:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Deploy Remaining Infrastructure
        id: deploy_infra
        if: steps.build_push.outcome == 'success'
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}"

      - name: Output API URL
        if: steps.deploy_infra.outcome == 'success'
        working-directory: ./terraform
        run: terraform output api_url

  cleanup-on-failure:
    needs: deploy
    if: ${{ needs.deploy.outputs.deployment_status == 'failure' || needs.deploy.result == 'failure' }}
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Set AWS Region
        run: echo "AWS_REGION=${{ github.event.inputs.aws_region || secrets.AWS_REGION || 'us-east-1' }}" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Ensure force_delete and force_destroy are true
        run: |
          if ! grep -q "force_delete = true" terraform/main.tf; then
            sed -i '/resource "aws_ecr_repository" "ai_doc_parser" {/a \ \ force_delete = true' terraform/main.tf
          fi
          if ! grep -q "force_destroy = true" terraform/main.tf; then
            sed -i '/resource "aws_s3_bucket" "ai_doc_parser" {/a \ \ force_destroy = true' terraform/main.tf
          fi

      - name: Empty S3 bucket if it exists
        run: |
          if aws s3 ls s3://ai-doc-parser-s3 2>&1 > /dev/null; then
            aws s3 rm s3://ai-doc-parser-s3 --recursive
          fi
        continue-on-error: true

      - name: Apply force_delete/force_destroy changes
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}"
        continue-on-error: true

      - name: Destroy Infrastructure
        working-directory: ./terraform
        run: |
          terraform destroy -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}"
        continue-on-error: true

      - name: Notify about cleanup status
        run: echo "Cleanup process completed. Please check AWS console to confirm all resources are removed."
