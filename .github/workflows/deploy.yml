name: Deploy AI Document Parser

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      aws_region:
        description: 'AWS Region to deploy to'
        required: false
        default: 'us-east-1'
      environment:
        description: 'Environment to deploy to'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}
    outputs:
      deployment_status: ${{ job.status }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set AWS Region
        id: set-region
        run: echo "AWS_REGION=${{ github.event.inputs.aws_region || secrets.AWS_REGION || 'us-east-1' }}" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        
      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Check if resources already exist
        id: check_resources
        run: |
          # Check if IAM role exists
          if aws iam get-role --role-name ai-doc-parser-lambda-role 2>/dev/null; then
            echo "IAM_ROLE_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "IAM_ROLE_EXISTS=false" >> $GITHUB_OUTPUT
          fi
          
          # Check if ECR repo exists
          if aws ecr describe-repositories --repository-names ai-doc-parser-ecr 2>/dev/null; then
            echo "ECR_REPO_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "ECR_REPO_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Import existing IAM role into Terraform state
        if: steps.check_resources.outputs.IAM_ROLE_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_iam_role.lambda_role ai-doc-parser-lambda-role
        continue-on-error: true

      - name: Import existing ECR repository into Terraform state
        if: steps.check_resources.outputs.ECR_REPO_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_ecr_repository.ai_doc_parser ai-doc-parser-ecr
        continue-on-error: true

      - name: Check if S3 bucket exists
        id: check_s3
        run: |
          if aws s3api head-bucket --bucket ai-doc-parser-s3 2>/dev/null; then
            echo "S3_BUCKET_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "S3_BUCKET_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Check if Lambda function exists
        id: check_lambda
        run: |
          if aws lambda get-function --function-name ai-doc-parser-lambda 2>/dev/null; then
            echo "LAMBDA_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "LAMBDA_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Check if API Gateway exists
        id: check_api
        run: |
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text)
          if [ ! -z "$API_ID" ]; then
            echo "API_EXISTS=true" >> $GITHUB_OUTPUT
            echo "API_ID=$API_ID" >> $GITHUB_OUTPUT
          else
            echo "API_EXISTS=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Import S3 bucket
        if: steps.check_s3.outputs.S3_BUCKET_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_s3_bucket.ai_doc_parser ai-doc-parser-s3
        continue-on-error: true

      - name: Import Lambda function
        if: steps.check_lambda.outputs.LAMBDA_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_lambda_function.ai_doc_parser ai-doc-parser-lambda
        continue-on-error: true

      - name: Import API Gateway
        if: steps.check_api.outputs.API_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          terraform import \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            aws_api_gateway_rest_api.api ${{ steps.check_api.outputs.API_ID }}
        continue-on-error: true

      - name: Import API Gateway Resources
        if: steps.check_api.outputs.API_EXISTS == 'true'
        working-directory: ./terraform
        run: |
          # First, get the API ID
          API_ID=${{ steps.check_api.outputs.API_ID }}
          
          # Try to import the root resource
          ROOT_RESOURCE_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/'].id" --output text)
          if [ ! -z "$ROOT_RESOURCE_ID" ]; then
            # Find the /api resource
            API_RESOURCE_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api'].id" --output text)
            if [ ! -z "$API_RESOURCE_ID" ]; then
              terraform import \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                aws_api_gateway_resource.api_resource $API_ID/$ROOT_RESOURCE_ID/$API_RESOURCE_ID || true
                
              # Find and import other resources
              PROCESS_DOC_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api/process-document'].id" --output text)
              TASK_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api/task'].id" --output text)
              TASK_ID_ID=$(aws apigateway get-resources --rest-api-id $API_ID --query "items[?path=='/api/task/{task_id}'].id" --output text)
              
              if [ ! -z "$PROCESS_DOC_ID" ]; then
                terraform import \
                  -var="aws_region=${{ env.AWS_REGION }}" \
                  -var="api_key=${{ secrets.API_KEY }}" \
                  -var="db_host=${{ secrets.DB_HOST }}" \
                  -var="db_name=${{ secrets.DB_NAME }}" \
                  -var="db_password=${{ secrets.DB_PASSWORD }}" \
                  -var="db_port=${{ secrets.DB_PORT }}" \
                  -var="db_user=${{ secrets.DB_USER }}" \
                  -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                  aws_api_gateway_resource.process_document $API_ID/$API_RESOURCE_ID/$PROCESS_DOC_ID || true
              fi
              
              if [ ! -z "$TASK_ID" ]; then
                terraform import \
                  -var="aws_region=${{ env.AWS_REGION }}" \
                  -var="api_key=${{ secrets.API_KEY }}" \
                  -var="db_host=${{ secrets.DB_HOST }}" \
                  -var="db_name=${{ secrets.DB_NAME }}" \
                  -var="db_password=${{ secrets.DB_PASSWORD }}" \
                  -var="db_port=${{ secrets.DB_PORT }}" \
                  -var="db_user=${{ secrets.DB_USER }}" \
                  -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                  aws_api_gateway_resource.task $API_ID/$API_RESOURCE_ID/$TASK_ID || true
              fi
              
              if [ ! -z "$TASK_ID_ID" ]; then
                terraform import \
                  -var="aws_region=${{ env.AWS_REGION }}" \
                  -var="api_key=${{ secrets.API_KEY }}" \
                  -var="db_host=${{ secrets.DB_HOST }}" \
                  -var="db_name=${{ secrets.DB_NAME }}" \
                  -var="db_password=${{ secrets.DB_PASSWORD }}" \
                  -var="db_port=${{ secrets.DB_PORT }}" \
                  -var="db_user=${{ secrets.DB_USER }}" \
                  -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                  aws_api_gateway_resource.task_id $API_ID/$TASK_ID/$TASK_ID_ID || true
              fi
            fi
          fi
        continue-on-error: true

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Terraform Plan
        working-directory: ./terraform
        run: |
          terraform plan \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}"

      - name: Create ECR Repository and IAM Roles
        id: create_ecr_iam
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_ecr_repository.ai_doc_parser \
            -target=aws_iam_role.lambda_role \
            -target=aws_iam_role_policy.lambda_s3_policy \
            -target=aws_iam_role_policy_attachment.lambda_logs
        continue-on-error: true
        
      - name: Check ECR IAM creation status
        if: steps.create_ecr_iam.outcome != 'success'
        run: |
          echo "ECR and IAM creation failed. This might be because they already exist."
          echo "Continuing with deployment..."

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Ensure Dockerfile is Lambda-compatible
        run: |
          # Ensure Dockerfile is using proper Lambda base image
          if ! grep -q "FROM public.ecr.aws/lambda/python:" Dockerfile; then
            echo "ERROR: Dockerfile doesn't use AWS Lambda base image. Please update your Dockerfile."
            exit 1
          fi
          
          # Ensure CMD is set correctly for Lambda
          if ! grep -q 'CMD \[ "lambda_handler.handler" \]' Dockerfile; then
            echo "Updating CMD for Lambda compatibility"
            # If CMD exists, replace it
            if grep -q "CMD " Dockerfile; then
              sed -i 's|CMD .*|CMD [ "lambda_handler.handler" ]|' Dockerfile
            else
              # Add CMD if it doesn't exist
              echo 'CMD [ "lambda_handler.handler" ]' >> Dockerfile
            fi
          fi

      - name: Build and push Docker image
        id: build_push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          platforms: linux/amd64
          tags: ${{ steps.login-ecr.outputs.registry }}/ai-doc-parser-ecr:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            LAMBDA_TASK_ROOT=/var/task
            AWS_LAMBDA_FUNCTION_HANDLER=lambda_handler.handler

      - name: Deploy S3 and API Gateway
        id: deploy_non_lambda
        if: steps.build_push.outcome == 'success'
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_s3_bucket.ai_doc_parser \
            -target=aws_s3_bucket_ownership_controls.ai_doc_parser \
            -target=aws_api_gateway_rest_api.api \
            -target=aws_api_gateway_resource.api_resource \
            -target=aws_api_gateway_resource.process_document \
            -target=aws_api_gateway_resource.task \
            -target=aws_api_gateway_resource.task_id \
            -target=aws_api_gateway_method.process_document_post \
            -target=aws_api_gateway_method.task_id_get
        continue-on-error: true

      - name: Update Lambda Function
        id: update_lambda
        if: steps.build_push.outcome == 'success'
        run: |
          # First check if Lambda exists
          if aws lambda get-function --function-name ai-doc-parser-lambda > /dev/null 2>&1; then
            # Update existing Lambda
            aws lambda update-function-code \
              --function-name ai-doc-parser-lambda \
              --image-uri ${{ steps.login-ecr.outputs.registry }}/ai-doc-parser-ecr:latest
          else
            # Try to create Lambda through Terraform
            cd terraform
            terraform apply -auto-approve \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              -target=aws_lambda_function.ai_doc_parser
          fi
        continue-on-error: true

      - name: Deploy API Gateway Integrations and Deployment
        id: deploy_integrations
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_api_gateway_integration.process_document_integration \
            -target=aws_api_gateway_integration.task_id_integration \
            -target=aws_lambda_permission.api_gateway \
            -target=aws_api_gateway_deployment.prod
        continue-on-error: true

      - name: Output API URL
        if: steps.deploy_integrations.outcome == 'success'
        working-directory: ./terraform
        run: terraform output api_url

  cleanup-on-failure:
    needs: deploy
    if: ${{ needs.deploy.outputs.deployment_status == 'failure' || needs.deploy.result == 'failure' }}
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Set AWS Region
        run: echo "AWS_REGION=${{ github.event.inputs.aws_region || secrets.AWS_REGION || 'us-east-1' }}" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Ensure force_delete and force_destroy are true
        run: |
          if ! grep -q "force_delete = true" terraform/main.tf; then
            sed -i '/resource "aws_ecr_repository" "ai_doc_parser" {/a \ \ force_delete = true' terraform/main.tf
          fi
          if ! grep -q "force_destroy = true" terraform/main.tf; then
            sed -i '/resource "aws_s3_bucket" "ai_doc_parser" {/a \ \ force_destroy = true' terraform/main.tf
          fi

      - name: Empty S3 bucket if it exists
        run: |
          if aws s3 ls s3://ai-doc-parser-s3 2>&1 > /dev/null; then
            aws s3 rm s3://ai-doc-parser-s3 --recursive
          fi
        continue-on-error: true

      - name: Apply force_delete/force_destroy changes
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}"
        continue-on-error: true

      - name: Destroy Infrastructure
        working-directory: ./terraform
        run: |
          terraform destroy -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}"
        continue-on-error: true

      - name: Notify about cleanup status
        run: echo "Cleanup process completed. Please check AWS console to confirm all resources are removed."
