name: Deploy AI Document Parser

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      aws_region:
        description: 'AWS Region to deploy to'
        required: false
        default: 'us-east-1'
      environment:
        description: 'Environment to deploy to'
        required: false
        default: 'production'
        type: choice
        options:
          - production
          - staging
          - development

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}
    outputs:
      deployment_status: ${{ job.status }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set AWS Region
        id: set-region
        run: echo "AWS_REGION=${{ github.event.inputs.aws_region || secrets.AWS_REGION || 'us-east-1' }}" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        
      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      # Clear Terraform state to avoid conflicts
      - name: Clear Terraform state for conflict-prone resources
        working-directory: ./terraform
        run: |
          terraform state rm aws_api_gateway_resource.api_resource || true
          terraform state rm aws_api_gateway_resource.process_document || true
          terraform state rm aws_api_gateway_resource.task || true
          terraform state rm aws_api_gateway_resource.task_id || true
          terraform state rm aws_lambda_function.ai_doc_parser || true
        continue-on-error: true

      # Basic resource imports
      - name: Import basic resources
        working-directory: ./terraform
        run: |
          # Import ECR repository if it exists
          if aws ecr describe-repositories --repository-names ai-doc-parser-ecr 2>/dev/null; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_ecr_repository.ai_doc_parser ai-doc-parser-ecr || true
          fi
          
          # Import IAM role if it exists
          if aws iam get-role --role-name ai-doc-parser-lambda-role 2>/dev/null; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_iam_role.lambda_role ai-doc-parser-lambda-role || true
          fi
          
          # Import S3 bucket if it exists
          if aws s3api head-bucket --bucket ai-doc-parser-s3 2>/dev/null; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_s3_bucket.ai_doc_parser ai-doc-parser-s3 || true
          fi
          
          # Import API Gateway if it exists
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text || echo "")
          if [ ! -z "$API_ID" ]; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_api_gateway_rest_api.api $API_ID || true
          fi
        continue-on-error: true

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Create ECR Repository and IAM Roles
        id: create_ecr_iam
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_ecr_repository.ai_doc_parser \
            -target=aws_iam_role.lambda_role \
            -target=aws_iam_role_policy.lambda_s3_policy \
            -target=aws_iam_role_policy_attachment.lambda_logs
        continue-on-error: true

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v2
        
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build and Push Docker Image for Lambda
        id: build_push
        run: |
          # Get ECR repository URI
          ECR_REPO=$(aws ecr describe-repositories --repository-names ai-doc-parser-ecr --query 'repositories[0].repositoryUri' --output text)
          
          # Login to ECR
          aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_REPO
          
          # Verify Dockerfile is using AWS Lambda base image
          if ! grep -q "FROM public.ecr.aws/lambda/python:" Dockerfile; then
            echo "ERROR: Dockerfile must use the AWS Lambda base image (public.ecr.aws/lambda/python)"
            cat Dockerfile
            exit 1
          fi
          
          # Build image specifically for Lambda (no buildx)
          echo "Building image for Lambda..."
          docker build -t $ECR_REPO:latest .
          
          # Push the image
          echo "Pushing image to ECR..."
          docker push $ECR_REPO:latest
          
          echo "The image has been built and pushed to $ECR_REPO:latest"

      - name: Deploy S3 Bucket
        id: deploy_s3
        working-directory: ./terraform
        run: |
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_s3_bucket.ai_doc_parser \
            -target=aws_s3_bucket_ownership_controls.ai_doc_parser
        continue-on-error: true

      - name: Create or Update Lambda Function
        id: deploy_lambda
        run: |
          # Get ECR repository URI
          ECR_REPO=$(aws ecr describe-repositories --repository-names ai-doc-parser-ecr --query 'repositories[0].repositoryUri' --output text)
          
          # Check if Lambda exists
          if aws lambda get-function --function-name ai-doc-parser-lambda > /dev/null 2>&1; then
            echo "Updating Lambda function..."
            aws lambda update-function-code \
              --function-name ai-doc-parser-lambda \
              --image-uri $ECR_REPO:latest
          else
            echo "Creating Lambda function..."
            # Create Lambda with more parameters
            aws lambda create-function \
              --function-name ai-doc-parser-lambda \
              --role arn:aws:iam::$(aws sts get-caller-identity --query 'Account' --output text):role/ai-doc-parser-lambda-role \
              --package-type Image \
              --code ImageUri=$ECR_REPO:latest \
              --timeout 90 \
              --memory-size 4096 \
              --architectures x86_64 \
              --ephemeral-storage Size=5120 \
              --environment "Variables={API_KEY=${{ secrets.API_KEY }},DB_HOST=${{ secrets.DB_HOST }},DB_NAME=${{ secrets.DB_NAME }},DB_PASSWORD=${{ secrets.DB_PASSWORD }},DB_PORT=${{ secrets.DB_PORT }},DB_USER=${{ secrets.DB_USER }},OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }},S3_BUCKET_NAME=ai-doc-parser-s3}"
          fi
          
          # Wait for Lambda to be ready
          echo "Waiting for Lambda to be ready..."
          aws lambda wait function-active-v2 --function-name ai-doc-parser-lambda
          
          echo "Lambda function deployed successfully"

      - name: Deploy API Gateway
        id: deploy_api
        working-directory: ./terraform
        run: |
          # Update Terraform configuration to use the lambda without creating it
          cat > lambda_override.tf << 'EOT'
          # This file overrides the creation of the Lambda function
          # since we created it using the AWS CLI
          resource "aws_lambda_function" "ai_doc_parser" {
            function_name = "ai-doc-parser-lambda"
            image_uri     = "${aws_ecr_repository.ai_doc_parser.repository_url}:latest"
            role          = aws_iam_role.lambda_role.arn
            package_type  = "Image"
            memory_size   = 4096
            timeout       = 90
            ephemeral_storage {
              size = 5120
            }

            environment {
              variables = {
                API_KEY         = var.api_key
                DB_HOST         = var.db_host
                DB_NAME         = var.db_name
                DB_PASSWORD     = var.db_password
                DB_PORT         = var.db_port
                DB_USER         = var.db_user
                OPENAI_API_KEY  = var.openai_api_key
                S3_BUCKET_NAME  = aws_s3_bucket.ai_doc_parser.bucket
              }
            }
            
            # Prevent terraform from trying to create the Lambda
            # (Lambda was created by aws cli)
            lifecycle {
              ignore_changes = all
            }
          }
          EOT
          
          # Import Lambda into state
          LAMBDA_ARN=$(aws lambda get-function --function-name ai-doc-parser-lambda --query 'Configuration.FunctionArn' --output text)
          if [ ! -z "$LAMBDA_ARN" ]; then
            terraform import \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              aws_lambda_function.ai_doc_parser $LAMBDA_ARN || true
          fi
          
          # Check if API Gateway resources exist and skip if they do
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text || echo "")
          
          if [ ! -z "$API_ID" ]; then
            # Get existing resources
            RESOURCES=$(aws apigateway get-resources --rest-api-id $API_ID)
            API_PATH_EXISTS=$(echo "$RESOURCES" | grep -c "/api" || true)
            
            if [ "$API_PATH_EXISTS" -gt 0 ]; then
              echo "API resources already exist, skipping resource creation"
              
              # Apply only lambda permissions and integration
              terraform apply -auto-approve \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                -target=aws_lambda_permission.api_gateway
            else
              # Apply all API Gateway resources
              terraform apply -auto-approve \
                -var="aws_region=${{ env.AWS_REGION }}" \
                -var="api_key=${{ secrets.API_KEY }}" \
                -var="db_host=${{ secrets.DB_HOST }}" \
                -var="db_name=${{ secrets.DB_NAME }}" \
                -var="db_password=${{ secrets.DB_PASSWORD }}" \
                -var="db_port=${{ secrets.DB_PORT }}" \
                -var="db_user=${{ secrets.DB_USER }}" \
                -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
                -target=aws_api_gateway_rest_api.api \
                -target=aws_api_gateway_resource.api_resource \
                -target=aws_api_gateway_resource.process_document \
                -target=aws_api_gateway_resource.task \
                -target=aws_api_gateway_resource.task_id \
                -target=aws_api_gateway_method.process_document_post \
                -target=aws_api_gateway_method.task_id_get \
                -target=aws_api_gateway_integration.process_document_integration \
                -target=aws_api_gateway_integration.task_id_integration \
                -target=aws_lambda_permission.api_gateway
            fi
          else
            # Create all resources
            terraform apply -auto-approve \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="api_key=${{ secrets.API_KEY }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_name=${{ secrets.DB_NAME }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
              -target=aws_api_gateway_rest_api.api \
              -target=aws_api_gateway_resource.api_resource \
              -target=aws_api_gateway_resource.process_document \
              -target=aws_api_gateway_resource.task \
              -target=aws_api_gateway_resource.task_id \
              -target=aws_api_gateway_method.process_document_post \
              -target=aws_api_gateway_method.task_id_get \
              -target=aws_api_gateway_integration.process_document_integration \
              -target=aws_api_gateway_integration.task_id_integration \
              -target=aws_lambda_permission.api_gateway
          fi
        continue-on-error: true

      - name: Deploy API Gateway Stage
        id: deploy_stage
        working-directory: ./terraform
        run: |
          # Create or update the deployment
          terraform apply -auto-approve \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="api_key=${{ secrets.API_KEY }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_name=${{ secrets.DB_NAME }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="openai_api_key=${{ secrets.OPENAI_API_KEY }}" \
            -target=aws_api_gateway_deployment.prod
            
          # Get API URL directly from AWS CLI since Terraform may have warnings
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text)
          if [ ! -z "$API_ID" ]; then
            API_URL="https://$API_ID.execute-api.${{ env.AWS_REGION }}.amazonaws.com/prod"
            echo "API Gateway URL: $API_URL"
            # Create a file to store the URL for future reference
            echo $API_URL > api_url.txt
          else
            echo "API Gateway not found"
            exit 1
          fi

  cleanup-on-failure:
    needs: deploy
    if: ${{ needs.deploy.outputs.deployment_status == 'failure' || needs.deploy.result == 'failure' }}
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Set AWS Region
        run: echo "AWS_REGION=${{ github.event.inputs.aws_region || secrets.AWS_REGION || 'us-east-1' }}" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Empty S3 bucket if it exists
        run: |
          if aws s3 ls s3://ai-doc-parser-s3 2>&1 > /dev/null; then
            aws s3 rm s3://ai-doc-parser-s3 --recursive
          fi
        continue-on-error: true

      - name: Delete Lambda Function
        run: |
          if aws lambda get-function --function-name ai-doc-parser-lambda > /dev/null 2>&1; then
            aws lambda delete-function --function-name ai-doc-parser-lambda
          fi
        continue-on-error: true

      - name: Delete API Gateway
        run: |
          API_ID=$(aws apigateway get-rest-apis --query "items[?name=='ai-doc-parser-api'].id" --output text)
          if [ ! -z "$API_ID" ]; then
            aws apigateway delete-rest-api --rest-api-id $API_ID
          fi
        continue-on-error: true

      - name: Delete IAM Role
        run: |
          if aws iam get-role --role-name ai-doc-parser-lambda-role > /dev/null 2>&1; then
            # First detach policies
            aws iam list-attached-role-policies --role-name ai-doc-parser-lambda-role --query 'AttachedPolicies[*].PolicyArn' --output text | tr '\t' '\n' | xargs -I {} aws iam detach-role-policy --role-name ai-doc-parser-lambda-role --policy-arn {}
            # Delete inline policies
            aws iam list-role-policies --role-name ai-doc-parser-lambda-role --query 'PolicyNames' --output text | tr '\t' '\n' | xargs -I {} aws iam delete-role-policy --role-name ai-doc-parser-lambda-role --policy-name {}
            # Delete role
            aws iam delete-role --role-name ai-doc-parser-lambda-role
          fi
        continue-on-error: true

      - name: Delete ECR Repository
        run: |
          if aws ecr describe-repositories --repository-names ai-doc-parser-ecr > /dev/null 2>&1; then
            aws ecr delete-repository --repository-name ai-doc-parser-ecr --force
          fi
        continue-on-error: true

      - name: Delete S3 Bucket
        run: |
          if aws s3api head-bucket --bucket ai-doc-parser-s3 2>/dev/null; then
            aws s3 rb s3://ai-doc-parser-s3 --force
          fi
        continue-on-error: true

      - name: Notify about cleanup status
        run: echo "Cleanup process completed. Please check AWS console to confirm all resources are removed."
